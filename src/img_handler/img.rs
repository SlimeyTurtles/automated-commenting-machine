use std::{ops::Add, time::Duration};

use crate::{config::Config, app_config::config};
use anyhow::{Context, Result};
use async_openai::types::{CreateImageRequestArgs, ImageModel, ResponseFormat::Url};
use dirs::home_dir;
use reqwest::Client;
use serde::Deserialize;

/// Stores a single commit message candidate generated by the model
#[derive(Deserialize)]
struct ImageCandidate {
    image_base64: String,
}

/// Stores all the commit message candidates generated by the model
#[derive(Deserialize)]
struct ImageCandidates {
    choices: Vec<ImageCandidate>,
}

pub async fn generate_image_url(
    img: &str,
) -> Result<String> {

    let config_file = home_dir()
        .context("Failed to retrieve config directory.")?
        .join(".acm/config.toml");

    let config = config::load_config(&config_file).await?;

    let http_client = Client::builder()
        .timeout(Duration::from_secs(config.request_timeout))
        .build()?;

    println!("Generating image of: {}", img);

    let payload = CreateImageRequestArgs::default()
        .model(ImageModel::Other(config.img_model_name.clone().into()))
        .prompt(img)
        .response_format(Url)
        .build()
        .context("Failed to construct the request payload")?;

    let response = http_client
        .post(format!("{}", &config.img_api_base_url))
        .bearer_auth(&config.api_key)
        .json(&payload)
        .send()
        .await
        .context("Failed to send the request to the Inference API provider")?
        .json::<ImageCandidates>()
        .await
        .context("Failed to parse the response from the API provider")?;

    let url = &response
        .choices
        .first() // Only the first generated commit message is used
        .context("No commit messages generated")?
        .image_base64;
    
    // let str: String = "data:image/png;base64,".to_string();

    Ok(url.to_string())
}
